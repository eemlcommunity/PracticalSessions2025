# [[EEML2025](https://www.eeml.eu)] Tutorial 2: Mechanistic Interpretability

**Authors:** Arthur Conmy and Federico Barbero


--- 

The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3 was announced in 2020, PaLM in 2022, many more LLMs since then), and yet we have no idea how they work nor how to write one ourselves. The goal of mechanistic interpretability is to try to fix this!

### Outline:

- 1️⃣ TransformerLens: Introduction
- 2️⃣ TransformerLens: Hooks
- 3️⃣ Bonus: Replicating Golden Gate Claude!


### Notebooks

Tutorial: [![Open In 
Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eemlcommunity/PracticalSessions2025/blob/main/2_mechanistic_interpretability/mechanistic_interpretability_tutorial.ipynb)

---
